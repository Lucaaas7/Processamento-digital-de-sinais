# -*- coding: utf-8 -*-
"""Trabalho 2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_HYd6LfeJCOZ3BQN-8X9r-MzCBSVwWa-
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.io import wavfile
import IPython.display as ipd

def plot(y,title,*args):
    plt.figure(figsize=(16,4))
    plt.title(title)
    if(args):
      plt.plot(args[0],y)
    else:
      plt.plot(y)
    plt.show()
    
def calcular_numero_de_zeros(vetor):
    return int(2**np.ceil(np.log2(len(vetor))) - len(vetor))

def complete_zeros(n, vector):
  return np.concatenate([vector, np.zeros(n)])

def get_fft_index(i,width):
  i_fft= '{:0{width}b}'.format(i, width = width)
  return int(i_fft[::-1],2)

def org_index_fft(size_fft):
  org_index_fft = []
  for i in np.arange(0,size_fft):
    numbits = int(np.ceil(np.log2(size_fft)))
    org_index_fft.append(get_fft_index(i,numbits))
  return org_index_fft

def wN(N, signal):
  return np.exp(signal*1j*2*np.pi/N)

def fft(fact,N, vec=[]):
  size_v = len(vec)//2
  p1 = vec[0:len(vec)//2]
  p2 = vec[len(vec)//2:]
  if size_v == 1:
    g = vec[0] + vec[1]
    h = vec[0] - vec[1]
    return np.array([g,h])
  else: 
    wNs_tam = size_v
    Wns = wN(N, -1)**[(fact*i) for i in np.arange(0,wNs_tam)]
    
    g = p1 + p2
    h = (p1 - p2)*Wns
    
    fact = fact*2
    
    g = fft(fact, N, g)
    h = fft(fact, N, h)
  fft_ = np.concatenate([g,h])
  if fact == 2:
    fft_ = fft_[org_index_fft(len(fft_))]
  return fft_

def inverse_fft(fact,N, vec):
    size_v = len(vec)//2
    p1 = vec[0:len(vec)//2]
    p2 = vec[len(vec)//2:]
    
    if size_v == 1:
      g = vec[0] + vec[1]
      h = vec[0] - vec[1]
      return np.array([g,h])
    
    else: 
      wNs_tam = size_v
      Wns = wN(N, 1)**[(fact*i) for i in np.arange(0,wNs_tam)]
      
      g = p1 + p2
      h = (p1 - p2)*Wns

      fact = fact*2
      
      g =inverse_fft(fact, N, g)
      h = inverse_fft(fact, N, h)
      
      fft_ = np.concatenate([g,h])
      if fact == 2:
        fft_ = (fft_[org_index_fft(len(fft_))])/N
      return fft_
    
def overlap_add(N, x , h ): 
  M = int(len(h))
  No = N - M + 1 
  num_blocks_x = int(np.ceil(len(x))/No)
  y = np.zeros(int(len(x)) + M-1, dtype='complex')

  not_div_flag = False

  if(len(x) % N != 0):
    not_div_flag = True


    h = complete_zeros((N-M),h)
    h_jw = fft(1, N, h)

    for i in np.arange(0,num_blocks_x):
      x_block = x[i*(No):(i+1)*No]
      x_block = complete_zeros(M-1, x_block)

      if(i == (num_blocks_x -1) and not_div_flag):
        num_zeros_add = N-len(x_block)
        x_block = np.concatenate([x_block, np.zeros(num_zeros_add)])

        x_block_jw = fft(1, N, x_block) 
        conv_temp = inverse_fft(1, N, h_jw*x_block_jw)
        y[i*No: (i*No + N)] += conv_temp
      return y
    
def overlap_save(N, x, h):
  M = int(len(h))
  L = N - M + 1 
  tam_x_in = L - (M-1)
  
  number_blocks_x = int(np.ceil(len(x)/L))
    
  y = np.zeros(0, dtype='complex')
  h = complete_zeros((N-M),h)
  not_div_flag = False
  
  if(len(x) % N != 0):
    not_div_flag = True

  x_block = np.concatenate([np.zeros(M-1), x[0: L]])
  
  conv_freq = fft(1, N,x_block)* fft(1, N, h)
  conv_temp = inverse_fft(1, N, conv_freq)
  
  y = np.concatenate([y,conv_temp[(M-1):]])
  for j in np.arange(1, number_blocks_x):
    x_block = x[j*L - (M-1) : ((j+1)*L)]
    
  if(j == (number_blocks_x -1) and not_div_flag):
    num_zeros_add = N-len(x_block)
    x_block = np.concatenate([x_block, np.zeros(num_zeros_add)])
    
    h_jw = fft(1, N, h)
    x_block_jw = fft(1, N, x_block)
    
    conv_temp = inverse_fft(1, N, h_jw*x_block_jw)
    
    y = np.concatenate([y,conv_temp[(M-1):]])
  return y

n = np.arange(0,125)
h = ((np.sinc(0.325*(n-62)))*(0.325))*(0.5-0.5*np.cos(2*np.pi*n/124))

h_jw = np.fft.fft(h)
plot(h, "Filtro no tempo")
plot(np.absolute(h_jw),"Magnitude do Filtro",np.linspace(0,2*np.pi, len(h)))
plot(np.angle(h_jw),"Fase do Filtro", np.linspace(0,2*np.pi, len(h)))

fs, data_voz = wavfile.read('voz.wav')
fs, data_ruido = wavfile.read('ruido.wav')

fff_voz = np.fft.fft(data_voz)

plot(np.real(data_voz), 'Sinal gravado: Voz',
     np.linspace(0,2*np.pi, len(data_voz)))
plot(np.absolute(fff_voz), 'Magnitude do FFT de voz',
     np.linspace(0,2*np.pi, len(fff_voz)))
plot(np.angle(fff_voz), 'Fase da FFT de voz',
     np.linspace(0,2*np.pi, len(fff_voz)))

fft_ruido = np.fft.fft(data_ruido)

plot(np.real(data_ruido), 'Sinal: Ruído senoidal',
     np.linspace(0,2*np.pi, len(data_ruido)))
plot(np.absolute(fft_ruido), 'Magnitude da fft do ruído senoidal',
     np.linspace(0,2*np.pi, len(fft_ruido)))
plot(np.angle(fft_ruido), 'Fase do fft da ruído senoidal',
     np.linspace(0,2*np.pi, len(fft_ruido)))

voz_com_ruido = data_voz + 0.1*data_ruido

voz_com_ruido_fft = np.fft.fft(voz_com_ruido)

plot(np.real(voz_com_ruido), 'Sinal de voz com ruído',
     np.linspace(0,2*np.pi, len(voz_com_ruido)))
plot(np.absolute(voz_com_ruido_fft), 'Magnitude da FFT do sinal de voz com ruído',
     np.linspace(0,2*np.pi, len(voz_com_ruido_fft)))
plot(np.angle(voz_com_ruido_fft), 'Fase da FFT do sinal de voz com ruído',
     np.linspace(0,2*np.pi, len(voz_com_ruido_fft)))

voz_filtrada_over_and_save = overlap_save(512, voz_com_ruido, h)

voz_filtrada_over_and_save_add = complete_zeros(
    calcular_numero_de_zeros(voz_filtrada_over_and_save),
    voz_filtrada_over_and_save)

voz_filtrada_save_fft = fft(1,
                            len(voz_filtrada_over_and_save_add),
                            voz_filtrada_over_and_save_add)

plot(np.absolute(voz_filtrada_save_fft),
     'Magnitude da voz filtrada',
     np.linspace(-np.pi,np.pi, len(voz_filtrada_save_fft)))
plot(np.angle(voz_filtrada_save_fft),
     'Fase da voz filtrada',
     np.linspace(-np.pi,np.pi, len(voz_filtrada_save_fft)))

wc1 = 1.8*(np.pi*2*1/8)
wc2 = 2.2*(np.pi*2*1/8)

ws1 = 1.9*(np.pi*2*1/8)
ws2 = 2.1*(np.pi*2*1/8)

wp1 = 2*wc1-ws1

deltaW = np.absolute(ws1-wp1)
deltaF = deltaW/(2*np.pi)

M = int(3.1/deltaF)

n = np.arange(0,M+1)

h_rejeita_faixa = np.zeros(M+1)

for i in np.arange(0,len(n)):
  
  if i != M/2:
    h_rejeita_faixa [i] = (1/((i - M/2)*np.pi))*(np.sin(wc1*(i - M/2)) - np.sin(wc2*(i - M/2)))*(0.5 - 0.5*np.cos(2*np.pi*i/M))
    
  else:
    h_rejeita_faixa[i] = 1 - ((wc2 -wc1)/np.pi)
    
plot(h_rejeita_faixa,'novo filtro')
h_rejeita_faixa_fft = np.fft.fft(h_rejeita_faixa)

plot(np.absolute(h_rejeita_faixa_fft),
     'Magnitude da fft do filtro rejeita faixa',
     np.linspace(0,2*np.pi, len(h_rejeita_faixa_fft)))
plot(np.angle(h_rejeita_faixa_fft),
     'Fase da fft do filtro rejeita faixa',
     np.linspace(0,2*np.pi, len(h_rejeita_faixa_fft)))

voz_novo_filtro_over_save= overlap_save(512, voz_com_ruido, h_rejeita_faixa)

voz_novo_filtro_over_save_fft = np.fft.fft(voz_novo_filtro_over_save)
plot(np.absolute(voz_novo_filtro_over_save_fft),
     'Magnitude da fft voz filtrada, convolução feita com algoritmo' + 
     'de Overlap-save', 
     np.linspace(0,2*np.pi, len(voz_novo_filtro_over_save_fft)))
plot(np.angle(voz_novo_filtro_over_save_fft), 
     'Fase da fft da voz filtrada,convolução feita com algoritmo' +
     'de Overlap-Save', 
     np.linspace(0,2*np.pi, len(voz_novo_filtro_over_save_fft)))